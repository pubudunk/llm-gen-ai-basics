{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20af8e8a-1117-43fa-b8b5-dfd275c38d91",
   "metadata": {},
   "source": [
    "### Langchain Tutorial: Chatbot with No Memory\n",
    "https://python.langchain.com/docs/tutorials/chatbot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c081603-4de0-458f-ae7c-742cb6cb1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain-core langgraph>0.2.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec571f66-a508-4604-82c8-5aff34e023bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API keys and environment variables\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# LangSmith can be used to debug / test / monitor AI Application \n",
    "\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "  os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key for LangSmith: \")\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c60d49-d718-4c1d-9e72-80cfad8ffad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c9294b0-5cd9-480d-97ea-322242344869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi Pubudu! Nice to meet you.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--7992ca8e-a804-4507-9dc2-ec8d2262ecc7-0', usage_metadata={'input_tokens': 8, 'output_tokens': 251, 'total_tokens': 259, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 242}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the model directly\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi! My Name is Pubudu\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef0e5c7e-4439-48c2-b4f0-a2e7057c6e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't know your name. I'm an AI and don't have access to personal information about you, including your name. My purpose is to assist you based on the information you provide during our conversation.\\n\\nHow can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--765d99e9-dccf-4beb-b7cf-fddf67cf0cb0-0', usage_metadata={'input_tokens': 7, 'output_tokens': 524, 'total_tokens': 531, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 471}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM does not have any context/memory\n",
    "model.invoke([HumanMessage(content=\"What's my name?\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27655663",
   "metadata": {},
   "source": [
    " You can check Langsmith traces of above converstion by login-in. Input/Output/Total Tokens/Latency etc\n",
    " \n",
    " https://www.langchain.com/\n",
    " \n",
    " To get around with context/memory problem, we can pass the entire 'Conversation History'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf5445f-baa8-4412-8132-8a8f785f9188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Pubudu!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--6a9004be-fe1d-4395-9629-d2500ac4b021-0', usage_metadata={'input_tokens': 35, 'output_tokens': 48, 'total_tokens': 83, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 42}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! My Name is Pubudu\"),\n",
    "        AIMessage(content=\"Hi Pubudu! It's nice to meet you. How can I help you today?\"),\n",
    "        HumanMessage(content=\"What's my name?\"),\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
